{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.data.numpy_dataset import from_numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a034f819",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc8f756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/tiggi/Documents/IU_projects/model_engineering/spam/mlruns/378166278007602301', creation_time=1759241664366, experiment_id='378166278007602301', last_update_time=1759241664366, lifecycle_stage='active', name='spam_filter_basline', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLOR_MAP = \"viridis\" #\"Greens\" \n",
    "\n",
    "plt.rcParams[\"image.cmap\"] = COLOR_MAP\n",
    "sns.set_theme(style=\"whitegrid\", palette= COLOR_MAP) \n",
    "\n",
    "current_dir = Path(os.getcwd()).resolve().parent\n",
    "RAW_DATA_PATH = current_dir / \"data\" / \"SMSSpamCollection.csv\"\n",
    "\n",
    "MLFLOW_TRACKING_URI = os.path.join(current_dir, \"mlruns\")\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "mlflow.set_experiment(\"spam_filter_basline\")    #store all subsequent runs under this same experiment ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27a249",
   "metadata": {},
   "source": [
    "### Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37ad7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning transformer:\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_special_chars(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    tokens = word_tokenize(text)                    # keeps punctuation/numbers as separate tokens\n",
    "    filtered = [w for w in tokens if w not in stop_words]\n",
    "    lemmas = [lemmatizer.lemmatize(w, pos=\"v\") for w in filtered]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.apply(clean_special_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5951b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameters for tuning\n",
    "\n",
    "param_grid = {\n",
    "    \"vectorizers\" : [CountVectorizer, TfidfVectorizer],\n",
    "    \"ngram_ranges\" : [(1,1), (1,2)],                      # vectorizer relates combinations of 1 word or 1&2 words\n",
    "    \"max_dfs\" : [0.95, 0.9],                              #  ignore too often words\n",
    "    \"min_dfs\" : [1, 5],                                   # ignore too rare words\n",
    "    \"alphas\" : [1.0, 0.1],                                # NB alpha: smoothing factor for bias handling \n",
    "    \"scores\": [\"accuracy\", \"f1_macro\", \"precision_macro\", \"recall_macro\", \"roc_auc\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"cleaner\", TextCleaner()),              \n",
    "    (\"vectorizer\", TfidfVectorizer()),       \n",
    "    (\"clf\", MultinomialNB())                 \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40d98bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'd', 'g']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"a\": \"b\", \"c\":'d', 'f':'g'}\n",
    "\n",
    "list(params.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384b40a2",
   "metadata": {},
   "source": [
    "StratifiedKFold keeps for every fold roughly the same ham/spam ratio as the full dataset\n",
    "use of cross validation for increasing the size of the dataset for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ae35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3ded75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gridsearch to xplore the parameters with cross validation: \n",
    "#from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "#grid = GridSearchCV(pipe, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dde75a8",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fc83b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(RAW_DATA_PATH, delimiter='\\t', header=None, encoding='utf-8', names=['label', 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "67df574f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[2]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0059bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
    "    data[\"text\"], data[\"label\"],\n",
    "    test_size=0.25, stratify=data[\"label\"], random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_holdout, y_holdout,\n",
    "    test_size=0.2, stratify=y_holdout, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986933a7",
   "metadata": {},
   "source": [
    "### train and find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112e53d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log datasets with mlflow\n",
    "train_input = from_numpy(X_train, name=\"train_data\", targets=y_train)\n",
    "val_input = from_numpy(X_val, name=\"val_data\", targets=y_val)\n",
    "test_input = from_numpy(X_test, name=\"test_data\", targets=y_test)\n",
    "\n",
    "mlflow.log_input(train_input, context=\"training\")\n",
    "mlflow.log_input(val_input, context=\"validation\")\n",
    "mlflow.log_input(test_input, context=\"testing\")\n",
    "\n",
    "# set manual search \n",
    "for vect_class in param_grid['vectorizers']:\n",
    "    for ngram in param_grid['ngram_ranges']:\n",
    "        for max_df in param_grid['max_dfs']:\n",
    "            for min_df in param_grid['min_dfs']:\n",
    "                for alpha in param_grid['alphas']:\n",
    "                    \n",
    "                    scoring = {\n",
    "                        \"accuracy\": \"accuracy\",\n",
    "                        \"f1_macro\": \"f1_macro\",\n",
    "                        \"precision_macro\": \"precision_macro\",\n",
    "                        \"recall_macro\": \"recall_macro\",\n",
    "                        \"roc_auc\": \"roc_auc\"\n",
    "                    }\n",
    "                    \n",
    "                    # vectorizer\n",
    "                    vect = vect_class(ngram_range=ngram, max_df=max_df, min_df=min_df)\n",
    "                    \n",
    "                    # pipeline\n",
    "                    pipe.set_params(vectorizer=vect, clf__alpha=alpha)\n",
    "                    \n",
    "                    # run CV\n",
    "                    \n",
    "                    # log params & results\n",
    "                    with mlflow.start_run(\n",
    "                        run_name = f'params ngram={ngram}, maxdf={max_df}, mindf {min_df}, alpha={alpha}',\n",
    "                        ):\n",
    "                        scores = cross_validate(\n",
    "                            pipe, \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            cv=skf, \n",
    "                            scoring= [\"accuracy\", \"f1_macro\", \"precision_macro\", \"recall_macro\", \"roc_auc\"],\n",
    "                            return_train_score=True,\n",
    "                        )\n",
    "                        print(scores)\n",
    "                                              \n",
    "\n",
    "                        # log params\n",
    "                        mlflow.log_param(\"vectorizer\", vect_class.__name__)\n",
    "                        mlflow.log_param(\"ngram_range\", ngram)\n",
    "                        mlflow.log_param(\"max_df\", max_df)\n",
    "                        mlflow.log_param(\"min_df\", min_df)\n",
    "                        mlflow.log_param(\"alpha\", alpha)\n",
    "\n",
    "                        # log metrics\n",
    "                        train_metrics = {\n",
    "                            \"train_accuracy\": np.mean(scores[\"train_accuracy\"]),\n",
    "                            \"train_f1_macro\": np.mean(scores[\"train_f1_macro\"]),\n",
    "                            \"train_precision_macro\": np.mean(scores[\"train_precision_macro\"]),\n",
    "                            \"train_recall_macro\": np.mean(scores[\"train_recall_macro\"]),\n",
    "                            \"train_roc_auc\": np.mean(scores[\"train_roc_auc\"]),\n",
    "                        }\n",
    "\n",
    "                        test_metrics = {\n",
    "                            \"test_accuracy\": np.mean(scores[\"test_accuracy\"]),\n",
    "                            \"test_f1_macro\": np.mean(scores[\"test_f1_macro\"]),\n",
    "                            \"test_precision_macro\": np.mean(scores[\"test_precision_macro\"]),\n",
    "                            \"test_recall_macro\": np.mean(scores[\"test_recall_macro\"]),\n",
    "                            \"test_roc_auc\": np.mean(scores[\"test_roc_auc\"]),\n",
    "                        }\n",
    "\n",
    "                        # log metrics\n",
    "                        for key, value in train_metrics.items():\n",
    "                            mlflow.log_metric(key, value)\n",
    "\n",
    "                        for key, value in test_metrics.items():\n",
    "                            mlflow.log_metric(key, value)\n",
    "                        \n",
    "\n",
    "                        print(f\"{vect_class.__name__}, ngram={ngram}, max_df={max_df}, min_df={min_df}, alpha={alpha}, F1={np.mean(scores[\"test_f1_macro\"]):.3f}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24265125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'74412e79045745ca987a981d871eba2a'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run = mlflow.search_runs(order_by=[\"metrics.test_precision_macro DESC\", \"metrics.test_f1_macro DESC\"])\n",
    "best_run_id = best_run['run_id'][0]\n",
    "best_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6289d0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorizer': 'TfidfVectorizer',\n",
       " 'max_df': '0.9',\n",
       " 'ngram_range': '(1, 2)',\n",
       " 'min_df': '1',\n",
       " 'alpha': '0.1'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "best_run = client.get_run(best_run_id)\n",
    "\n",
    "best_params = best_run.data.params\n",
    "best_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37189aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sklearn.feature_extraction.text.CountVectorizer,\n",
       " sklearn.feature_extraction.text.TfidfVectorizer]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid['vectorizers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a42e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_and_log_best_model(best_run_id, pipe, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"find retrain and log the best model\"\"\"\n",
    "    \n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    best_run = client.get_run(best_run_id)\n",
    "\n",
    "    best_params = best_run.data.params\n",
    "\n",
    "    vectorizer_map = {\n",
    "    \"CountVectorizer\": CountVectorizer,\n",
    "    \"TfidfVectorizer\": TfidfVectorizer\n",
    "        }\n",
    "    vect_class = vectorizer_map[best_params[\"vectorizer\"]]\n",
    "    vect = vect_class(\n",
    "        ngram_range=eval(best_params[\"ngram_range\"]),\n",
    "        max_df=float(best_params[\"max_df\"]),\n",
    "        min_df=int(best_params[\"min_df\"])\n",
    "        )\n",
    "    \n",
    "    # update pipeline\n",
    "    pipe.set_params(vectorizer=vect, clf__alpha=float(best_params[\"alpha\"]))\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # fit model\n",
    "    with mlflow.start_run(run_name=\"best_model\") as run:\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_val_pred = pipe.predict(X_val)\n",
    "        y_val_proba = pipe.predict_proba(X_val)[:, 1]\n",
    "\n",
    "        precision = precision_score(y_val, y_val_pred, average=\"macro\")\n",
    "        f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "        recall = recall_score(y_val, y_val_pred, average=\"macro\")\n",
    "        roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"precision_macro\", precision)\n",
    "        mlflow.log_metric(\"f1_macro\", f1)\n",
    "        mlflow.log_metric(\"recall_macro\", recall)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        mlflow.sklearn.log_model(pipe, name=\"model\", input_example=X_val[:5].to_frame(name=\"text\"))\n",
    "\n",
    "        print(f\"Final model trained and logged. Precision: {precision:.3f}, F1: {f1:.3f}, ROC-AUC: {roc_auc}\")\n",
    "        return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "388e546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3fe32f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/13 21:47:31 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model trained and logged. Precision: 0.988, F1: 0.966, ROC-AUC: 0.9933195020746888\n"
     ]
    }
   ],
   "source": [
    "trained_pipeline = retrain_and_log_best_model(\n",
    "    best_run_id=best_run_id,\n",
    "    pipe=pipe,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd858274",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
